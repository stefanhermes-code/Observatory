# Report generation: filtering mechanisms and order of operations

## 1. Filtering mechanisms (detailed)

Filtering happens in **three places**: Evidence Engine (before persist), Intelligence Writer (before markdown), and Content Pipeline (during HTML rendering). Each is described below.

---

### A. Evidence Engine (`core/evidence_engine.py`) — before persist

Applied to the raw candidate set (ingestion + web search) **before** any candidate is inserted into `candidate_articles`.

| Filter | What it does | Effect |
|--------|----------------|--------|
| **URL presence/prefix** | Drops items with no `url` or URL not starting with `http://` or `https://`. | Item is not persisted. |
| **Date range** | Keeps only items whose `published_at` is inside `[lookback_date, reference_date]` (from cadence + app date). Items with no date are kept. Uses `is_in_date_range()`. | Item outside range is not persisted. |
| **Canonical dedupe** | After canonicalizing URL, if that canonical URL was already seen in this run, skip. | Duplicate (by canonical URL) is not persisted. |
| **URL validation (optional)** | When `validate_urls=True`, calls `validate_url()` and stores `validation_status` and `http_status` on the row. | Does **not** remove the item; status is stored for later use. |

So at persist time: only **valid URL prefix**, **in-date** (or no date), and **deduped** candidates are stored. No filtering by HTTP 2xx here.

---

### B. Intelligence Writer (`core/intelligence_writer.py`) — before markdown

Applied to the list of candidates read from `candidate_articles` **before** building the report text (markdown). No HTML exists yet.

| Filter | What it does | Effect |
|--------|----------------|--------|
| **Meta-snippet (title)** | If `title` matches patterns like "Here are the most relevant…", "search results for the query…", "presented as titles", etc. (`_META_SNIPPET_PATTERNS`), the candidate is excluded. | Item is not included in any section. |
| **Meta-snippet (snippet)** | Same patterns applied to `snippet`. | Item is not included in any section. |
| **Date range (again)** | When `lookback_date` and `reference_date` are provided, keeps only candidates whose `published_at` is in range (or missing). Uses `is_in_date_range()`. | Item outside range is not included in the report. |
| **Minimum evidence** | If after the above filters the number of candidates is below `min_evidence` (default 3), the writer does not build the full report; it returns a "Coverage low" message instead. | Whole report is replaced by a short coverage message. |

So at writer output: only **non-meta** and **in-date** candidates are turned into bullets in the markdown. The writer does **not** check whether the URL returns 2xx.

---

### C. Content Pipeline (`core/content_pipeline.py`) — during HTML rendering

Applied when turning the writer’s **markdown** into the final **HTML**. Two kinds of filtering:

**C1. Content-level (text stripping, before parsing bullets)**  
Applied to the full markdown string. These do not remove “items” as such; they remove or normalize text so that only real content and list items remain.

- Duplicate/main title line (e.g. "HTC Global Market Intelligence" at start).
- Metadata lines (Generated:, Frequency:, Regions:, Coverage:, Cadence:, Scope:).
- Phase 1/2/3/4 sections and Notes on Methodology.
- CRITICAL: … warnings.
- "[No qualifying…]" / "[No…detected…]" blocks.
- Methodology/process sentences (e.g. "The output was generated by…", "Only actionable…included…", "Filtering was applied…", etc.).
- Company-list / region-coverage explanations.
- Standalone date-only lines (e.g. "Nov 19, 2025" on its own).
- Lines that are **only** a URL (no other text).
- " — web_search" / " — web search" in text.
- Numbered list lines normalized to bullets (`1. ` → `- `).

**C2. Item-level (per bullet that looks like a news item)**  
For each line that is a bullet (`- …` or `* …`), the pipeline parses it into: main text, source, date, URL(s). Then it applies these filters **before** emitting any HTML for that item:

| Filter | What it does | Effect |
|--------|----------------|--------|
| **Date outside lookback** | If a date was parsed and it falls **outside** the report’s lookback window, the item is skipped. | Item is not added to the HTML list (no `<li>`). |
| **No source** | If no source could be extracted (and no "Source not specified" fallback), the item is skipped. | Item is not added to the HTML list. |
| **No URL** | If the bullet has no URL, the item is skipped. | Item is not added to the HTML list. |
| **Invalid URL** | If the URL is empty or does not start with `http://` or `https://`, the item is skipped. | Item is not added to the HTML list. |
| **URL does not work** | If `_url_returns_ok(url)` is false (e.g. HTTP not 2xx, timeout), the item is skipped. | Item is not added to the HTML list. |

Only after an item passes all of C2 do we build the formatted `<li>…</li>` (title as link, source, date) and append it. So **item-level filtering is done before formatting that item into HTML**.

---

## 2. Is filtering done before formatting?

**Yes, in the sense that matters for “what appears in the report”:**

- **Evidence Engine:** Filtering is done **before** any report exists; only the filtered set is persisted and then used by the writer.
- **Intelligence Writer:** Filtering (meta-snippet, date, min evidence) is done **before** producing the markdown. The markdown is built only from the filtered candidate list.
- **Content Pipeline:**  
  - **Content-level** (meta stripping, URL-only lines, etc.) is done **before** we split into lines and parse bullets.  
  - **Item-level** (date, source, URL presence, URL validity, URL returns 2xx) is done **before** we output the formatted `<li>…</li>` for that item. So each item is filtered first; only then is it formatted and appended.

So: nothing is “formatted into the report” and then removed later. Filtering always happens **before** the corresponding formatting step (persist, markdown section, or HTML list item).

---

## 3. Order of operations (high level)

1. **Evidence Engine:** Ingest + search → URL/date/dedupe (and optional URL validation stored) → **persist** filtered candidates.
2. **Generator:** Load candidates for run → **Intelligence Writer:** meta + date filter → build markdown (structure + bullets).
3. **Content Pipeline:** Strip meta/content noise → split into lines → for each bullet: parse → **apply item filters** → if pass, **format one `<li>`** and append → wrap in full HTML document.

So the mechanism is: **filter first, then format** at each stage (persist, markdown, HTML item).
